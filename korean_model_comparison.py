#!/usr/bin/env python3
"""
ë‹¤ì–‘í•œ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸
K-pop í€´ì¦ˆ ì¤‘ë³µ ê²€ì‚¬ì— ê°€ì¥ ì í•©í•œ ëª¨ë¸ ì„ íƒ
"""

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import logging
import time
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í…ŒìŠ¤íŠ¸í•  í•œêµ­ì–´ ëª¨ë¸ë“¤
KOREAN_MODELS = [
    "jhgan/ko-sroberta-multitask",
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", 
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    "sentence-transformers/distiluse-base-multilingual-cased-v2",
    "BM-K/KoSimCSE-roberta-multitask",
    "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
]

# ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
TEST_DATASETS = {
    "ë°ë·”_ê´€ë ¨": [
        "BTSì˜ ë°ë·” ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?",
        "BTSê°€ ë°ë·”í•œ í•´ëŠ”?", 
        "ë°©íƒ„ì†Œë…„ë‹¨ì´ ì–¸ì œ ì‹œì‘í–ˆë‚˜ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì˜ ì²« í™œë™ì€?",
        "BTSëŠ” ì–¸ì œë¶€í„° í™œë™ì„ ì‹œì‘í–ˆë‚˜ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì´ ì²˜ìŒ ë‚˜ì˜¨ ì—°ë„ëŠ”?"
    ],
    
    "ë©¤ë²„_ê´€ë ¨": [
        "BTS ë©¤ë²„ëŠ” ëª‡ ëª…ì¸ê°€ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì€ ì´ ëª‡ ëª…ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
        "BTSì˜ êµ¬ì„±ì› ìˆ˜ëŠ”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ ë©¤ë²„ ìˆ˜ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
        "BTSëŠ” ëª‡ ëª…ì˜ ë©¤ë²„ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‚˜ìš”?"
    ],
    
    "ë¦¬ë”_ê´€ë ¨": [
        "BTSì˜ ë¦¬ë”ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì˜ ë¦¬ë”ëŠ”?",
        "BTS íŒ€ì¥ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì„ ì´ë„ëŠ” ì‚¬ëŒì€?"
    ],
    
    "ìŒì•…_ê´€ë ¨": [
        "BTSì˜ ëŒ€í‘œê³¡ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ì˜ íˆíŠ¸ê³¡ì€?",
        "BTSì˜ ìœ ëª…í•œ ë…¸ë˜ëŠ”?",
        "ë°©íƒ„ì†Œë…„ë‹¨ ì¸ê¸°ê³¡ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    ],
    
    "ì™„ì „_ë‹¤ë¥¸_ì£¼ì œ": [
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?",
        "ì‚¬ê³¼ëŠ” ë¹¨ê°„ìƒ‰ì…ë‹ˆë‹¤",
        "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”",
        "ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
        "ì¶•êµ¬ ê²½ê¸°ëŠ” ì–¸ì œ ì‹œì‘í•˜ë‚˜ìš”?"
    ]
}

def load_model_safely(model_name):
    """ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
    try:
        logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        start_time = time.time()
        model = SentenceTransformer(model_name)
        load_time = time.time() - start_time
        logger.info(f"ë¡œë”© ì™„ë£Œ: {load_time:.2f}ì´ˆ")
        return model, load_time
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ {model_name}: {e}")
        return None, None

def calculate_intra_group_similarity(embeddings):
    """ê·¸ë£¹ ë‚´ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°"""
    if len(embeddings) < 2:
        return 0.0
    
    similarities = []
    for i in range(len(embeddings)):
        for j in range(i+1, len(embeddings)):
            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]
            similarities.append(sim)
    
    return np.mean(similarities)

def calculate_inter_group_similarity(group1_embeddings, group2_embeddings):
    """ê·¸ë£¹ ê°„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°"""
    similarities = []
    for emb1 in group1_embeddings:
        for emb2 in group2_embeddings:
            sim = cosine_similarity([emb1], [emb2])[0][0]
            similarities.append(sim)
    
    return np.mean(similarities)

def evaluate_model_performance(model, model_name):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    logger.info(f"\n=== {model_name} ì„±ëŠ¥ í‰ê°€ ===")
    
    results = {
        "model_name": model_name,
        "intra_group_similarities": {},
        "inter_group_similarities": {},
        "encoding_time": 0,
        "dimension": 0
    }
    
    # ëª¨ë“  ë¬¸ì¥ ì„ë² ë”© ìƒì„±
    all_embeddings = {}
    start_time = time.time()
    
    for group_name, sentences in TEST_DATASETS.items():
        embeddings = []
        for sentence in sentences:
            embedding = model.encode(sentence)
            embeddings.append(embedding)
        all_embeddings[group_name] = embeddings
    
    encoding_time = time.time() - start_time
    results["encoding_time"] = encoding_time
    results["dimension"] = len(all_embeddings[list(TEST_DATASETS.keys())[0]][0])
    
    logger.info(f"ì„ë² ë”© ì°¨ì›: {results['dimension']}")
    logger.info(f"ì¸ì½”ë”© ì‹œê°„: {encoding_time:.2f}ì´ˆ")
    
    # ê·¸ë£¹ ë‚´ ìœ ì‚¬ë„ ê³„ì‚°
    logger.info("\n--- ê·¸ë£¹ ë‚´ ìœ ì‚¬ë„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) ---")
    for group_name, embeddings in all_embeddings.items():
        if group_name != "ì™„ì „_ë‹¤ë¥¸_ì£¼ì œ":  # ì™„ì „ ë‹¤ë¥¸ ì£¼ì œëŠ” ì œì™¸
            intra_sim = calculate_intra_group_similarity(embeddings)
            results["intra_group_similarities"][group_name] = intra_sim
            logger.info(f"{group_name}: {intra_sim:.4f}")
    
    # ê·¸ë£¹ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê´€ë ¨ ì—†ëŠ” ê·¸ë£¹ë“¤)
    logger.info("\n--- ê·¸ë£¹ ê°„ ìœ ì‚¬ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) ---")
    group_names = [name for name in TEST_DATASETS.keys() if name != "ì™„ì „_ë‹¤ë¥¸_ì£¼ì œ"]
    
    for i, group1 in enumerate(group_names):
        for j, group2 in enumerate(group_names):
            if i < j:
                inter_sim = calculate_inter_group_similarity(
                    all_embeddings[group1], 
                    all_embeddings[group2]
                )
                pair_name = f"{group1}_vs_{group2}"
                results["inter_group_similarities"][pair_name] = inter_sim
                logger.info(f"{group1} vs {group2}: {inter_sim:.4f}")
    
    # ì™„ì „ ë‹¤ë¥¸ ì£¼ì œì™€ì˜ ìœ ì‚¬ë„ (ë§¤ìš° ë‚®ì•„ì•¼ í•¨)
    logger.info("\n--- ì™„ì „ ë‹¤ë¥¸ ì£¼ì œì™€ì˜ ìœ ì‚¬ë„ (ë§¤ìš° ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) ---")
    for group_name in group_names:
        different_sim = calculate_inter_group_similarity(
            all_embeddings[group_name],
            all_embeddings["ì™„ì „_ë‹¤ë¥¸_ì£¼ì œ"]
        )
        results["inter_group_similarities"][f"{group_name}_vs_ì™„ì „ë‹¤ë¥¸ì£¼ì œ"] = different_sim
        logger.info(f"{group_name} vs ì™„ì „ë‹¤ë¥¸ì£¼ì œ: {different_sim:.4f}")
    
    return results

def calculate_model_score(results):
    """ëª¨ë¸ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
    score = 0
    
    # 1. ê·¸ë£¹ ë‚´ ìœ ì‚¬ë„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) - ê°€ì¤‘ì¹˜ 40%
    intra_avg = np.mean(list(results["intra_group_similarities"].values()))
    score += intra_avg * 0.4
    
    # 2. ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œ ê°„ ìœ ì‚¬ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) - ê°€ì¤‘ì¹˜ 30%
    different_topic_sims = [
        sim for key, sim in results["inter_group_similarities"].items() 
        if "ì™„ì „ë‹¤ë¥¸ì£¼ì œ" in key
    ]
    different_avg = np.mean(different_topic_sims)
    score += (1 - different_avg) * 0.3  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ 1ì—ì„œ ë¹¼ê¸°
    
    # 3. ê´€ë ¨ ì£¼ì œ ê°„ ì ì ˆí•œ êµ¬ë¶„ (ë„ˆë¬´ ë†’ì§€ë„ ë‚®ì§€ë„ ì•Šê²Œ) - ê°€ì¤‘ì¹˜ 20%
    related_sims = [
        sim for key, sim in results["inter_group_similarities"].items() 
        if "ì™„ì „ë‹¤ë¥¸ì£¼ì œ" not in key
    ]
    related_avg = np.mean(related_sims)
    # 0.6~0.8 ë²”ìœ„ê°€ ì´ìƒì  (ê´€ë ¨ìˆì§€ë§Œ êµ¬ë¶„ë˜ëŠ” ìˆ˜ì¤€)
    if 0.6 <= related_avg <= 0.8:
        related_score = 1.0
    else:
        related_score = 1.0 - abs(related_avg - 0.7) / 0.3
    score += related_score * 0.2
    
    # 4. ì†ë„ ë³´ë„ˆìŠ¤ (5ì´ˆ ì´í•˜ë©´ ë³´ë„ˆìŠ¤) - ê°€ì¤‘ì¹˜ 10%
    if results["encoding_time"] <= 5.0:
        speed_bonus = 0.1
    else:
        speed_bonus = max(0, 0.1 - (results["encoding_time"] - 5.0) * 0.01)
    score += speed_bonus
    
    return min(score, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ

def compare_specific_cases(model, model_name):
    """íŠ¹ì • ì¤‘ë³µ ê²€ì‚¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    logger.info(f"\n=== {model_name} ì¤‘ë³µ ê²€ì‚¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    # ì‹¤ì œ ì¤‘ë³µ ê²€ì‚¬ì—ì„œ ì¤‘ìš”í•œ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "original": "BTSì˜ ë°ë·” ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?",
            "candidates": [
                "BTSê°€ ë°ë·”í•œ í•´ëŠ”?",  # ë†’ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
                "ë°©íƒ„ì†Œë…„ë‹¨ì´ ì–¸ì œ ì‹œì‘í–ˆë‚˜ìš”?",  # ì¤‘ê°„ ìœ ì‚¬ë„ ì˜ˆìƒ
                "BTS ë©¤ë²„ëŠ” ëª‡ ëª…ì¸ê°€ìš”?",  # ë‚®ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
                "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?"  # ë§¤ìš° ë‚®ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
            ]
        },
        {
            "original": "ë°©íƒ„ì†Œë…„ë‹¨ì˜ ë¦¬ë”ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
            "candidates": [
                "BTSì˜ ë¦¬ë”ëŠ”?",  # ë†’ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
                "ë°©íƒ„ì†Œë…„ë‹¨ íŒ€ì¥ì€ ëˆ„êµ¬ì¸ê°€ìš”?",  # ë†’ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
                "BTSì˜ ëŒ€í‘œê³¡ì€ ë¬´ì—‡ì¸ê°€ìš”?",  # ë‚®ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
                "íŒŒì´ì¬ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”"  # ë§¤ìš° ë‚®ì€ ìœ ì‚¬ë„ ì˜ˆìƒ
            ]
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        logger.info(f"\n--- ì¼€ì´ìŠ¤ {i}: {case['original']} ---")
        
        original_embedding = model.encode(case['original'])
        
        for candidate in case['candidates']:
            candidate_embedding = model.encode(candidate)
            similarity = cosine_similarity([original_embedding], [candidate_embedding])[0][0]
            
            # ìœ ì‚¬ë„ ìˆ˜ì¤€ íŒë‹¨
            if similarity > 0.9:
                level = "ë§¤ìš° ë†’ìŒ ğŸ”¥"
            elif similarity > 0.8:
                level = "ë†’ìŒ âœ…"
            elif similarity > 0.6:
                level = "ì¤‘ê°„ âš ï¸"
            elif similarity > 0.4:
                level = "ë‚®ìŒ âŒ"
            else:
                level = "ë§¤ìš° ë‚®ìŒ â›”"
            
            logger.info(f"  vs '{candidate}': {similarity:.4f} ({level})")

def main():
    """ë©”ì¸ ë¹„êµ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("=== í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì¢…í•© ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
    
    all_results = []
    successful_models = []
    
    # ê° ëª¨ë¸ í…ŒìŠ¤íŠ¸
    for model_name in KOREAN_MODELS:
        try:
            model, load_time = load_model_safely(model_name)
            if model is None:
                continue
                
            # ì„±ëŠ¥ í‰ê°€
            results = evaluate_model_performance(model, model_name)
            results["load_time"] = load_time
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            score = calculate_model_score(results)
            results["total_score"] = score
            
            # íŠ¹ì • ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
            compare_specific_cases(model, model_name)
            
            all_results.append(results)
            successful_models.append((model_name, model))
            
            logger.info(f"\n{model_name} ì¢…í•© ì ìˆ˜: {score:.4f}")
            
        except Exception as e:
            logger.error(f"{model_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            continue
    
    # ìµœì¢… ê²°ê³¼ ì •ë¦¬
    logger.info("\n" + "="*80)
    logger.info("ğŸ† ìµœì¢… ëª¨ë¸ ìˆœìœ„")
    logger.info("="*80)
    
    # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
    all_results.sort(key=lambda x: x["total_score"], reverse=True)
    
    for i, result in enumerate(all_results, 1):
        logger.info(f"\n{i}ìœ„: {result['model_name']}")
        logger.info(f"   ì¢…í•© ì ìˆ˜: {result['total_score']:.4f}")
        logger.info(f"   ë¡œë”© ì‹œê°„: {result['load_time']:.2f}ì´ˆ")
        logger.info(f"   ì¸ì½”ë”© ì‹œê°„: {result['encoding_time']:.2f}ì´ˆ")
        logger.info(f"   ì„ë² ë”© ì°¨ì›: {result['dimension']}")
        
        # ê·¸ë£¹ ë‚´ í‰ê·  ìœ ì‚¬ë„
        intra_avg = np.mean(list(result["intra_group_similarities"].values()))
        logger.info(f"   ê·¸ë£¹ ë‚´ í‰ê·  ìœ ì‚¬ë„: {intra_avg:.4f}")
        
        # ì™„ì „ ë‹¤ë¥¸ ì£¼ì œì™€ì˜ í‰ê·  ìœ ì‚¬ë„
        different_sims = [
            sim for key, sim in result["inter_group_similarities"].items() 
            if "ì™„ì „ë‹¤ë¥¸ì£¼ì œ" in key
        ]
        different_avg = np.mean(different_sims)
        logger.info(f"   ë‹¤ë¥¸ ì£¼ì œì™€ í‰ê·  ìœ ì‚¬ë„: {different_avg:.4f}")
    
    # ì¶”ì²œ ëª¨ë¸
    if all_results:
        best_model = all_results[0]
        logger.info(f"\nğŸ¯ ì¶”ì²œ ëª¨ë¸: {best_model['model_name']}")
        logger.info(f"   ì´ìœ : ì¢…í•© ì ìˆ˜ {best_model['total_score']:.4f}ë¡œ 1ìœ„")
        
        # ì‹¤ìš©ì„± ê³ ë ¤ ì¶”ì²œ
        practical_models = [r for r in all_results if r['load_time'] < 10 and r['encoding_time'] < 10]
        if practical_models:
            practical_best = practical_models[0]
            logger.info(f"\nâš¡ ì‹¤ìš©ì„± ê³ ë ¤ ì¶”ì²œ: {practical_best['model_name']}")
            logger.info(f"   ì´ìœ : ì„±ëŠ¥ê³¼ ì†ë„ì˜ ê· í˜•ì´ ì¢‹ìŒ")
    
    logger.info("\n=== ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    
    return all_results

if __name__ == "__main__":
    results = main()
