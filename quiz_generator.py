import warnings
import os
# Suppress all deprecation warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)
# Also suppress via environment variable
os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'
from typing import TypedDict, Annotated, List
import operator
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_aws import ChatBedrock  # For Amazon Bedrock
from ddgs import DDGS
import json
import csv
from io import StringIO
from datetime import datetime
import time  # ì§€ì—° ì¶”ê°€
from botocore.config import Config  # Config ì„í¬íŠ¸ ì¶”ê°€

# OpenSearch ì„¤ì • ë° í•¨ìˆ˜ë“¤ import
from opensearch_config import (
    check_duplicate_in_opensearch,
    save_quiz_to_opensearch,
    get_opensearch_stats
)
from config import DEFAULT_DUPLICATION_THRESHOLD

# LLM setup - Using Amazon Bedrock Claude 3.7 Sonnet with cross-region inference
retry_config = Config(
    retries={
        'max_attempts': 10,
        'mode': 'adaptive'  # Exponential backoff for throttling
    }
)
llm = ChatBedrock(
    model_id="us.anthropic.claude-3-7-sonnet-20250219-v1:0",  # Claude 3.7 Sonnet cross-region profile
    region_name="us-east-1",  # Primary region; routes to us-east-1, us-east-2, us-west-2
    config=retry_config,
    # Add credentials if needed: credentials_profile_name="default"
)

# Current date
CURRENT_DATE = datetime(2025, 7, 25)

# Define quiz sub-task structure
class QuizSubTask(TypedDict):
    idol: str
    quiz_type: str  # e.g., "military_discharge", "latest_song"
    search_keyword: str  # Generated by LLM

# Global state
class State(TypedDict):
    topic: str  # User input topic
    all_subtasks: List[QuizSubTask]  # All subtasks to process
    current_subtask_index: int  # Current processing index
    current_subtask: QuizSubTask  # Currently processing subtask
    current_quiz: dict  # Currently generated quiz
    completed_quizzes: Annotated[List[dict], operator.add]  # Aggregated quizzes
    final_output: str  # Final CSV string
    
    # Control flags
    all_completed: bool  # All subtasks completed
    retry_feedback: str  # Feedback for retry from validation
    validation_success: bool  # Validation success flag
    duplication_check_success: bool  # Duplication check success flag
    retry_count: int  # Current retry count for current subtask

# Worker state is no longer needed - using main State for everything

# Orchestrator node: Manages quiz types sequentially
def orchestrator(state: State):
    # ì´ˆê¸° ì‹¤í–‰: ì „ì²´ subtasks ìƒì„±
    if 'topic' in state and not state.get('all_subtasks'):
        print("[orch]ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹œì‘: í† í”½ ì²˜ë¦¬ ì¤‘ -", state['topic'])
        time.sleep(1)
        topic = state['topic']
        
        # LLM prompt to generate sub-tasks
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="ë‹¹ì‹ ì€ K-pop ì•„ì´ëŒ í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì…ë‹ˆë‹¤. í˜„ì¬ ë‚ ì§œ: 2025-07-25. ì£¼ì œë¥¼ ë¶„ì„í•˜ê³  3-5ê°œì˜ í•˜ìœ„ ì‘ì—…ì„ JSON ë°°ì—´ë¡œ ìƒì„±í•˜ì„¸ìš”. ê° ê°ì²´ëŠ” idol, quiz_type (military_discharge, song_matching, latest_song, lyrics_blank, true_false, running_time, kpop_history, fill_blank ì¤‘ ì„ íƒ), search_keyword í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."),
            HumanMessage(content=f"ì£¼ì œ: {topic}")
        ])
        print("[orch]LLM í˜¸ì¶œ: sub-task ìƒì„± ì¤‘...")
        response = llm.invoke(prompt.format_messages())
        print("[orch]LLM ì‘ë‹µ ì›ë³¸:", response.content)
        
        try:
            quiz_subtasks = json.loads(response.content.strip())
            print("[orch]sub-tasks ìƒì„± ì™„ë£Œ:", quiz_subtasks)
            
            return {
                "all_subtasks": quiz_subtasks,
                "current_subtask_index": 0,
                "current_subtask": quiz_subtasks[0],
                "retry_count": 0
            }
        except json.JSONDecodeError:
            print("[orch]JSON íŒŒì‹± ì—ëŸ¬ ë°œìƒ")
            return {"all_subtasks": [], "all_completed": True}
    
    # í€´ì¦ˆ ì™„ë£Œ í›„: ë‹¤ìŒ í€´ì¦ˆíƒ€ì…ìœ¼ë¡œ ì´ë™
    elif state.get('completed_quizzes') and not state.get('all_completed'):
        current_index = state.get('current_subtask_index', 0)
        next_index = current_index + 1
        all_subtasks = state.get('all_subtasks', [])
        
        if next_index < len(all_subtasks):
            print(f"[orch]ë‹¤ìŒ í€´ì¦ˆíƒ€ì… ì‹œì‘: {next_index + 1}/{len(all_subtasks)}")
            return {
                "current_subtask_index": next_index,
                "current_subtask": all_subtasks[next_index],
                "retry_feedback": "",  # ìƒˆ í€´ì¦ˆíƒ€ì…ì´ë¯€ë¡œ í”¼ë“œë°± ì´ˆê¸°í™”
                "retry_count": 0  # ìƒˆ í€´ì¦ˆíƒ€ì…ì´ë¯€ë¡œ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê¸°í™”
            }
        else:
            print("[orch]ëª¨ë“  í€´ì¦ˆíƒ€ì… ì™„ë£Œ")
            return {"all_completed": True}
    
    # ì´ë¯¸ ì™„ë£Œëœ ê²½ìš°
    else:
        return {"all_completed": True}

# Search and Generate worker: Combines search and quiz generation with retry feedback
def search_and_generate(state: State):
    subtask = state['current_subtask']
    retry_feedback = state.get('retry_feedback', '')
    
    if retry_feedback:
        print(f"[search_gen]ì¬ì‹œë„ ì‹œì‘: {subtask['idol']} - {subtask['quiz_type']}")
        print(f"[search_gen]í”¼ë“œë°±: {retry_feedback}")
    else:
        print(f"[search_gen]ê²€ìƒ‰+ìƒì„± ì›Œì»¤ ì‹œì‘: {subtask['idol']} - {subtask['quiz_type']}")
    
    # Step 1: Search
    print("[search_gen]1ë‹¨ê³„: ê²€ìƒ‰ ì‹œì‘")
    time.sleep(1)
    
    # Generate optimal search keyword (í”¼ë“œë°± ê³ ë ¤)
    search_prompt_content = "í€´ì¦ˆ ìœ í˜•ê³¼ ì•„ì´ëŒì„ ê¸°ë°˜ìœ¼ë¡œ DuckDuckGo APIì— ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„±í•˜ì„¸ìš”. ê´€ë ¨ì´ ìˆë‹¤ë©´ í˜„ì¬ ë‚ ì§œ 2025-07-25ë¥¼ í¬í•¨í•˜ì„¸ìš”. í‚¤ì›Œë“œ ë¬¸ìì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    if retry_feedback:
        search_prompt_content += f" ì´ì „ ì‹œë„ê°€ ë‹¤ìŒ í”¼ë“œë°±ìœ¼ë¡œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {retry_feedback}. ì´ì— ë”°ë¼ ê²€ìƒ‰ ì „ëµì„ ì¡°ì •í•˜ì„¸ìš”."
    
    search_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=search_prompt_content),
        HumanMessage(content=f"ì•„ì´ëŒ: {subtask['idol']}, ìœ í˜•: {subtask['quiz_type']}, ì´ˆê¸° í‚¤ì›Œë“œ: {subtask['search_keyword']}")
    ])

    print(f"[search_gen]-[search_prompt] : {search_prompt}")

    refined_keyword = llm.invoke(search_prompt.format_messages()).content.strip()
    
    
    # Perform search with Korean region
    print(f"[search_gen]í•œêµ­ì–´ ê²€ìƒ‰ ì‹¤í–‰: {refined_keyword}")
    try:
        with DDGS() as ddgs:
            search_results = ddgs.text(
                query=refined_keyword,
                region="kr-kr",  # í•œêµ­ì–´ region ì„¤ì •
                max_results=5
            )
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            results = ""
            for i, result in enumerate(search_results):
                results += f"ì œëª©: {result.get('title', '')}\n"
                results += f"ë‚´ìš©: {result.get('body', '')}\n"
                results += f"URL: {result.get('href', '')}\n\n"
            print(f"[search_gen]ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì‹ : {search_results}ê°œ ê²°ê³¼")
    except Exception as e:
        print(f"[search_gen]ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        results = "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # Parse search results
    time.sleep(1)
    parse_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê´€ë ¨ ì •ë³´(ì˜ˆ: ì „ì—­ì¼, ë…¸ë˜, ê°€ì‚¬)ê°€ í¬í•¨ëœ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì„¸ìš”. 2025-07-25 ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§í•˜ì„¸ìš”. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."),
        HumanMessage(content=f"ê²€ìƒ‰ ê²°ê³¼: {results}")
    ])
    parsed_data = llm.invoke(parse_prompt.format_messages()).content.strip()
    
    try:
        # Clean JSON from markdown blocks
        if "```json" in parsed_data:
            parsed_data = parsed_data.split("```json")[1].split("```")[0].strip()
        elif "```" in parsed_data:
            parsed_data = parsed_data.split("```")[1].strip()
        data = json.loads(parsed_data)
        print("[search_gen]ê²€ìƒ‰ ë°ì´í„° íŒŒì‹± ì™„ë£Œ")
    except json.JSONDecodeError:
        print(f"[search_gen]ê²€ìƒ‰ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {parsed_data[:100]}...")
        data = {}
    
    # Step 2: Generate Quiz (í”¼ë“œë°± ê³ ë ¤)
    print("[search_gen]2ë‹¨ê³„: í€´ì¦ˆ ìƒì„± ì‹œì‘")
    time.sleep(1)
    
    quiz_prompt_content = "ê¸°ë°˜ ë°ì´í„°ë¥¼ ì°¸ê³ í•´ì„œ K-pop í€´ì¦ˆë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”: {'QuizID': int, 'Category': str, 'QuestionID': int, 'Type': str, 'Question': str, 'Options': list[str], 'IsCorrect': str}. 2ê°œ ë˜ëŠ” 4ê°œ ì„ íƒì§€ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ë¹ˆì¹¸ ë¬¸ì œë¡œ ë§Œë“œì„¸ìš”. ê¸°ì¤€ ë‚ ì§œ: 2025-07-25. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    if retry_feedback:
        quiz_prompt_content += f" ì´ì „ í€´ì¦ˆê°€ ë‹¤ìŒ í”¼ë“œë°±ìœ¼ë¡œ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤: {retry_feedback}. ìƒˆ í€´ì¦ˆì—ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”."
    
    quiz_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=quiz_prompt_content),
        HumanMessage(content=f"ìœ í˜•: {subtask['quiz_type']}, ì•„ì´ëŒ: {subtask['idol']}, ê¸°ë°˜ ë°ì´í„°: {data}")
    ])
    quiz_json = llm.invoke(quiz_prompt.format_messages()).content.strip()
    
    try:
        # Clean JSON from markdown blocks
        if "```json" in quiz_json:
            quiz_json = quiz_json.split("```json")[1].split("```")[0].strip()
        elif "```" in quiz_json:
            quiz_json = quiz_json.split("```")[1].strip()
        quiz = json.loads(quiz_json)
        print(f"[search_gen]í€´ì¦ˆ ìƒì„± ì™„ë£Œ: {quiz}")
    except json.JSONDecodeError:
        print(f"[search_gen]í€´ì¦ˆ ìƒì„± íŒŒì‹± ì‹¤íŒ¨: {quiz_json[:100]}...")
        quiz = {}
    
    result_msg = "ì¬ì‹œë„ ì™„ë£Œ" if retry_feedback else "ê²€ìƒ‰+ìƒì„± ì™„ë£Œ"
    print(f"[search_gen]{result_msg}: {subtask['idol']} - {'ì„±ê³µ' if quiz else 'ì‹¤íŒ¨'}")
    
    return {"current_quiz": quiz if quiz else None}

# OpenSearch Duplication Checker: ì¤‘ë³µ í€´ì¦ˆ ê²€ì‚¬
def os_duplication_checker(state: State):
    print("[dup]OpenSearch ì¤‘ë³µ ê²€ì‚¬ ì›Œì»¤ ì‹œì‘...")
    print(f"[dup]State í‚¤ë“¤: {list(state.keys())}")
    
    quiz = state.get('current_quiz')
    
    if not quiz:
        print("[dup]ê²€ì‚¬í•  í€´ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤")
        # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:
            print(f"[dup]ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({retry_count}ë²ˆ), ë‹¤ìŒ í€´ì¦ˆíƒ€ì…ìœ¼ë¡œ ì´ë™")
            return {"duplication_check_success": True, "retry_count": 0, "retry_feedback": ""}
        
        return {"retry_feedback": "í€´ì¦ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "retry_count": retry_count + 1, "duplication_check_success": False}
    
    print(f"[dup]ì¤‘ë³µ ê²€ì‚¬ ëŒ€ìƒ í€´ì¦ˆ: {quiz.get('Question', '')}")
    
    # OpenSearch ì¤‘ë³µ ê²€ì‚¬ ìˆ˜í–‰
    question_text = quiz.get('Question', '')
    if not question_text:
        print("[dup]ì§ˆë¬¸ í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ì¤‘ë³µ ê²€ì‚¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
        return {"duplication_check_success": True, "retry_feedback": ""}
    
    try:
        print(f"[dup]OpenSearchì—ì„œ ì¤‘ë³µ í€´ì¦ˆ ê²€ì‚¬ ì¤‘... (ì„ê³„ê°’: {DEFAULT_DUPLICATION_THRESHOLD})")
        is_duplicate, duplicates, error = check_duplicate_in_opensearch(question_text, threshold=DEFAULT_DUPLICATION_THRESHOLD)
        
        if error:
            print(f"[dup]OpenSearch ì¤‘ë³µ ê²€ì‚¬ ì˜¤ë¥˜: {error}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ (ê²€ì¦ì€ ê³„ì†)
            return {"duplication_check_success": True, "retry_feedback": ""}
        
        if is_duplicate:
            print(f"[dup]ğŸš¨ ì¤‘ë³µ í€´ì¦ˆ ë°œê²¬! {len(duplicates)}ê°œì˜ ìœ ì‚¬í•œ í€´ì¦ˆ ì¡´ì¬")
            
            # í˜„ì¬ í€´ì¦ˆ ì •ë³´ ìˆ˜ì§‘
            current_quiz_info = f"""ğŸ“ í˜„ì¬ ìƒì„±ëœ í€´ì¦ˆ:
ì§ˆë¬¸: '{question_text}'
ì •ë‹µ: '{quiz.get('IsCorrect', '')}'
ì¹´í…Œê³ ë¦¬: {quiz.get('Category', '')}"""
            
            # ì¤‘ë³µ í€´ì¦ˆ ì •ë³´ ì¶œë ¥ ë° ìˆ˜ì§‘
            duplicate_info = []
            for i, dup in enumerate(duplicates[:3], 1):  # ìƒìœ„ 3ê°œë§Œ
                duplicate_info.append(f"{i}. '{dup['question']}' (ìœ ì‚¬ë„: {dup['cosine_similarity']:.3f})")
                print(f"[dup]  ìœ ì‚¬ í€´ì¦ˆ {i}: {dup['question']} (ìœ ì‚¬ë„: {dup['cosine_similarity']:.3f})")
            
            # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
            retry_count = state.get('retry_count', 0)
            if retry_count >= 3:
                print(f"[dup]ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({retry_count}ë²ˆ), ì¤‘ë³µ í€´ì¦ˆ ì²˜ë¦¬ - ë‹¤ìŒ í€´ì¦ˆíƒ€ì…ìœ¼ë¡œ ì´ë™")
                return {"duplication_check_success": True, "retry_count": 0, "retry_feedback": ""}
            
            # ì¤‘ë³µ í”¼ë“œë°± ìƒì„± (í˜„ì¬ í€´ì¦ˆ ì •ë³´ í¬í•¨)
            duplicate_feedback = f"""ğŸš¨ ì¤‘ë³µ í€´ì¦ˆ ê°ì§€ë¨! (ìœ ì‚¬ë„ ì„ê³„ê°’: {DEFAULT_DUPLICATION_THRESHOLD})

{current_quiz_info}

ğŸ” ê¸°ì¡´ ìœ ì‚¬ í€´ì¦ˆë“¤:
{chr(10).join(duplicate_info)}

ğŸ’¡ í•´ê²° ë°©ì•ˆ: 
- ë‹¤ë¥¸ ê°ë„ì—ì„œ ì ‘ê·¼í•˜ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”
- ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì´ë‚˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë£¨ëŠ” í€´ì¦ˆë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”
- ì‹œê°„ëŒ€, ìƒí™©, ë§¥ë½ ë“±ì„ ë‹¤ë¥´ê²Œ í•˜ì—¬ ì°¨ë³„í™”ëœ í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”"""
            
            print(f"[dup]ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨ - search_and_generateë¡œ ì¬ì‹œë„ ìš”ì²­")
            return {
                "retry_feedback": duplicate_feedback, 
                "retry_count": retry_count + 1, 
                "duplication_check_success": False
            }
        else:
            print("[dup]âœ… ì¤‘ë³µ ê²€ì‚¬ í†µê³¼ - ìƒˆë¡œìš´ í€´ì¦ˆì…ë‹ˆë‹¤!")
            return {"duplication_check_success": True, "retry_feedback": ""}
            
    except Exception as e:
        print(f"[dup]OpenSearch ì¤‘ë³µ ê²€ì‚¬ ì˜ˆì™¸ ë°œìƒ: {e}")
        # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
        return {"duplication_check_success": True, "retry_feedback": ""}

# Validation worker: Validates quiz and routes based on success/failure
def validation_worker(state: State):
    print("[val]ê²€ì¦ ì›Œì»¤ ì‹œì‘: í€´ì¦ˆ ê²€ì¦ ì¤‘...")
    print(f"[val]State í‚¤ë“¤: {list(state.keys())}")
    print(f"[val]current_quiz ì¡´ì¬ ì—¬ë¶€: {'current_quiz' in state}")
    time.sleep(1)
    quiz = state.get('current_quiz')
    
    if not quiz:
        print("[val]ê²€ì¦í•  í€´ì¦ˆê°€ ì—†ìŠµë‹ˆë‹¤")
        print(f"[val]current_quiz ê°’: {quiz}")
        
        # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
            print(f"[val]ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({retry_count}ë²ˆ), í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨ ì²˜ë¦¬ - ë‹¤ìŒ í€´ì¦ˆíƒ€ì…ìœ¼ë¡œ ì´ë™")
            return {"completed_quizzes": [], "validation_success": True, "retry_count": 0, "retry_feedback": ""}  # ë¹ˆ í€´ì¦ˆë¡œ ë‹¤ìŒìœ¼ë¡œ ì´ë™
        
        return {"retry_feedback": "í€´ì¦ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "retry_count": retry_count + 1}
    
    print(f"[val]í€´ì¦ˆ ë°œê²¬: {quiz}")
    
    # Step 1: Generate multiple validation keywords using LLM
    print("[val]1ë‹¨ê³„: ê²€ì¦ìš© í‚¤ì›Œë“œ ìƒì„±")
    keyword_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ì£¼ì–´ì§„ í€´ì¦ˆë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•œ 3-5ê°œì˜ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”. ê° í‚¤ì›Œë“œëŠ” í€´ì¦ˆì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ê²€ì¦í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆ: [\"í‚¤ì›Œë“œ1\", \"í‚¤ì›Œë“œ2\", \"í‚¤ì›Œë“œ3\"]"),
        HumanMessage(content=f"í€´ì¦ˆ: {json.dumps(quiz, ensure_ascii=False)}")
    ])
    
    try:
        keyword_response = llm.invoke(keyword_prompt.format_messages()).content.strip()
        # Clean JSON from markdown blocks
        if "```json" in keyword_response:
            keyword_response = keyword_response.split("```json")[1].split("```")[0].strip()
        elif "```" in keyword_response:
            keyword_response = keyword_response.split("```")[1].strip()
        
        validation_keywords = json.loads(keyword_response)
        print(f"[val]ê²€ì¦ í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ: {validation_keywords}")
    except json.JSONDecodeError:
        print(f"[val]í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©: {keyword_response[:100]}...")
        # ê¸°ë³¸ í‚¤ì›Œë“œ ìƒì„±
        key_fact = quiz.get('IsCorrect', '')
        question = quiz.get('Question', '')
        validation_keywords = [
            f"{key_fact}",
            f"{question}",
            f"K-pop {quiz.get('Category', '')}"
        ]
    
    # Step 2: Perform multiple searches with different keywords
    print("[val]2ë‹¨ê³„: ë‹¤ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤í–‰")
    all_search_results = []
    
    for i, keyword in enumerate(validation_keywords):
        print(f"[val]ê²€ìƒ‰ {i+1}/{len(validation_keywords)}: {keyword}")
        try:
            with DDGS() as ddgs:
                search_results = ddgs.text(
                    query=keyword,
                    region="kr-kr",  # í•œêµ­ì–´ region ì„¤ì •
                    max_results=2  # í‚¤ì›Œë“œë‹¹ 2ê°œì”©
                )
                
                for result in search_results:
                    all_search_results.append({
                        'keyword': keyword,
                        'title': result.get('title', ''),
                        'body': result.get('body', ''),
                        'url': result.get('href', '')
                    })
                    
            print(f"[val]í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            time.sleep(0.5)  # ê²€ìƒ‰ ê°„ ì§€ì—°
            
        except Exception as e:
            print(f"[val]í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            continue
    
    print(f"[val]ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_search_results)}ê°œ ê²°ê³¼")
    
    # Step 3: Aggregate and format search results
    print("[val]3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ì·¨í•© ë° ê²€ì¦")
    aggregated_results = ""
    for i, result in enumerate(all_search_results):
        aggregated_results += f"[í‚¤ì›Œë“œ: {result['keyword']}]\n"
        aggregated_results += f"ì œëª©: {result['title']}\n"
        aggregated_results += f"ë‚´ìš©: {result['body']}\n"
        aggregated_results += f"URL: {result['url']}\n\n"
    
    # Step 4: LLM validation with aggregated search results
    time.sleep(1)
    validate_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ë‹¹ì‹ ì€ í€´ì¦ˆê°€ í‹€ë¦° ì •ë³´ë¡œ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ ê²€ì¦í•˜ëŠ” ê²€ì¦ìì…ë‹ˆë‹¤. ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í€´ì¦ˆì˜ ì •í™•ì„±ì„ ê²€ì¦í•˜ì„¸ìš”. ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì¼ê´€ëœ ì •ë³´ê°€ í™•ì¸ë˜ë©´ 'VALID'ë¥¼ ë°˜í™˜í•˜ê³ , ëª¨ìˆœë˜ê±°ë‚˜ í™•ì¸ë˜ì§€ ì•Šìœ¼ë©´ 'INVALID: [êµ¬ì²´ì ì¸ í‹€ë¦° ì´ìœ ]'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”. 2025-07-25 ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ êµì°¨ í™•ì¸í•˜ì„¸ìš”."),
        HumanMessage(content=f"í€´ì¦ˆ: {json.dumps(quiz, ensure_ascii=False)}\n\në‹¤ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼:\n{aggregated_results}")
    ])
    validated = llm.invoke(validate_prompt.format_messages()).content.strip()
    print(f"[val]ì¢…í•© ê²€ì¦ ì‘ë‹µ: {validated}")
    
    if "INVALID" in validated.upper():
        # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
            print(f"[val]ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({retry_count}ë²ˆ), í€´ì¦ˆ ê²€ì¦ ì‹¤íŒ¨ ì²˜ë¦¬ - ë‹¤ìŒ í€´ì¦ˆíƒ€ì…ìœ¼ë¡œ ì´ë™")
            return {"completed_quizzes": [], "validation_success": True, "retry_count": 0, "retry_feedback": ""}  # ë¹ˆ í€´ì¦ˆë¡œ ë‹¤ìŒìœ¼ë¡œ ì´ë™
        
        # ì‹¤íŒ¨: search_and_generateë¡œ í”¼ë“œë°±ê³¼ í•¨ê»˜ ì¬ì‹œë„
        feedback = validated.replace("INVALID:", "").strip()
        print(f"[val]í€´ì¦ˆ ê²€ì¦ ì‹¤íŒ¨: {feedback}")
        return {"retry_feedback": feedback, "retry_count": retry_count + 1, "validation_success": False}  # validation_success=False ì¶”ê°€
    else:
        # ì„±ê³µ: orchestratorë¡œ ê²°ê³¼ ì „ë‹¬
        print("[val]í€´ì¦ˆ ê²€ì¦ ì„±ê³µ")
        return {"completed_quizzes": [quiz], "validation_success": True, "retry_count": 0, "retry_feedback": ""}

# Display worker: Synthesizes quizzes into CSV
def display_worker(state: State):
    print("[dp]í‘œì‹œ ì›Œì»¤ ì‹œì‘: OpenSearch ì €ì¥ í›„ CSV ìƒì„± ì¤‘...")
    quizzes = state['completed_quizzes']
    
    print(f"[dp]CSV ìƒì„± ì™„ë£Œ: í€´ì¦ˆ ê°œìˆ˜ {len(quizzes)}")
    
    # ===== 1ë‹¨ê³„: OpenSearchì— í€´ì¦ˆ ì €ì¥ =====
    print("[dp]1ë‹¨ê³„: OpenSearchì— í€´ì¦ˆ ì €ì¥ ì¤‘...")
    opensearch_success_count = 0
    opensearch_fail_count = 0
    
    for i, quiz in enumerate(quizzes, 1):
        print(f"[dp]OpenSearch ì €ì¥ {i}/{len(quizzes)}: {quiz.get('Question', '')[:50]}...")
        
        success, doc_id, error = save_quiz_to_opensearch(quiz)
        
        if success:
            opensearch_success_count += 1
            print(f"[dp]  âœ… ì €ì¥ ì„±ê³µ (ID: {doc_id})")
        else:
            opensearch_fail_count += 1
            print(f"[dp]  âŒ ì €ì¥ ì‹¤íŒ¨: {error}")
    
    print(f"[dp]OpenSearch ì €ì¥ ì™„ë£Œ: ì„±ê³µ {opensearch_success_count}ê°œ, ì‹¤íŒ¨ {opensearch_fail_count}ê°œ")
    
    # ===== 2ë‹¨ê³„: CSV ìƒì„± =====
    print("[dp]2ë‹¨ê³„: CSV íŒŒì¼ ìƒì„± ì¤‘...")
    output = StringIO()
    writer = csv.DictWriter(output, fieldnames=["QuizID", "Category", "QuestionID", "Type", "Question", "Option", "IsCorrect"])
    writer.writeheader()
    
    for quiz in quizzes:
        # CSV í–‰ ìƒì„±
        for option in quiz.get('Options', []):
            row = {
                "QuizID": quiz.get('QuizID', ''),
                "Category": quiz.get('Category', ''),
                "QuestionID": quiz.get('QuestionID', ''),
                "Type": quiz.get('Type', ''),
                "Question": quiz.get('Question', ''),
                "Option": option,
                "IsCorrect": "Y" if option == quiz.get('IsCorrect', '') else ""
            }
            writer.writerow(row)
    
    final_csv = output.getvalue()
    
    # ===== 3ë‹¨ê³„: CSV íŒŒì¼ ì €ì¥ =====
    topic = state.get('topic', 'quiz')
    safe_topic = topic.replace(' ', '_').replace('/', '_').lower()
    filename = f"{safe_topic}_quiz_output.csv"
    
    try:
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            f.write(final_csv)
        print(f"[dp]CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
    except Exception as e:
        print(f"[dp]CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print(f"[dp]í‘œì‹œ ì›Œì»¤ ì™„ë£Œ: OpenSearch {opensearch_success_count}ê°œ ì €ì¥, CSV íŒŒì¼ ìƒì„±")
    return {"final_output": final_csv}

# Routing functions
def route_after_validation(state: State):
    retry_feedback = state.get('retry_feedback', '')
    validation_success = state.get('validation_success', False)
    
    print(f"[route]ë¼ìš°íŒ… ì²´í¬: retry_feedback='{retry_feedback}', validation_success={validation_success}")
    
    if validation_success:
        return "success"  # validation_successê°€ Trueë©´ ë¬´ì¡°ê±´ ì„±ê³µìœ¼ë¡œ
    elif retry_feedback and retry_feedback.strip():  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¬ì‹œë„
        return "retry"  # ì‹¤íŒ¨ì‹œ search_and_generateë¡œ ì¬ì‹œë„
    else:
        return "retry"  # ê¸°ë³¸ê°’

def route_after_orchestrator(state: State):
    if state.get('all_completed'):
        return "display"  # ëª¨ë“  í€´ì¦ˆ ì™„ë£Œì‹œ display_workerë¡œ
    else:
        return "generate"  # ë‹¤ìŒ í€´ì¦ˆíƒ€ì… ì²˜ë¦¬

# Conditional edge: No longer needed for parallel processing
def assign_workers(state: State):
    # This function is no longer used in sequential processing
    return []

# Routing functions
def route_after_orchestrator(state: State):
    print(f"[route]ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í›„ ë¼ìš°íŒ…: all_completed={state.get('all_completed', False)}")
    if state.get('all_completed', False):
        return "display"
    else:
        return "generate"

def route_after_duplication_check(state: State):
    """ì¤‘ë³µ ê²€ì‚¬ í›„ ë¼ìš°íŒ…"""
    duplication_success = state.get('duplication_check_success', True)
    retry_feedback = state.get('retry_feedback', '')
    
    print(f"[route]ì¤‘ë³µ ê²€ì‚¬ í›„ ë¼ìš°íŒ…: duplication_success={duplication_success}, retry_feedback='{retry_feedback[:50]}...'")
    
    if duplication_success:
        return "validation"  # ì¤‘ë³µ ê²€ì‚¬ í†µê³¼ â†’ ê¸°ì¡´ ê²€ì¦ìœ¼ë¡œ
    else:
        return "retry"  # ì¤‘ë³µ ë°œê²¬ â†’ ì¬ì‹œë„

def route_after_validation(state: State):
    validation_success = state.get('validation_success', False)
    retry_feedback = state.get('retry_feedback', '')
    
    print(f"[route]ë¼ìš°íŒ… ì²´í¬: retry_feedback='{retry_feedback}', validation_success={validation_success}")
    
    if validation_success:
        return "success"
    else:
        return "retry"

# Build the graph
builder = StateGraph(State)

builder.add_node("orchestrator", orchestrator)
builder.add_node("search_and_generate", search_and_generate)
builder.add_node("os_duplication_checker", os_duplication_checker)  # ìƒˆë¡œìš´ ì¤‘ë³µ ê²€ì‚¬ ë…¸ë“œ
builder.add_node("validation_worker", validation_worker)
builder.add_node("display_worker", display_worker)

# ë¼ìš°íŒ… ì„¤ì •
builder.add_edge(START, "orchestrator")
builder.add_conditional_edges("orchestrator", route_after_orchestrator, 
                             {"generate": "search_and_generate", "display": "display_worker"})
builder.add_edge("search_and_generate", "os_duplication_checker")  # ìƒì„± í›„ ì¤‘ë³µ ê²€ì‚¬
builder.add_conditional_edges("os_duplication_checker", route_after_duplication_check,
                             {"validation": "validation_worker", "retry": "search_and_generate"})  # ì¤‘ë³µ ê²€ì‚¬ í›„ ë¶„ê¸°
builder.add_conditional_edges("validation_worker", route_after_validation,
                             {"retry": "search_and_generate", "success": "orchestrator"})
builder.add_edge("display_worker", END)

graph = builder.compile()

# Invoke example
input_state = {"topic": "Generate 5 quizzes about BTS"}
print("ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘: ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
try:
    final_state = graph.invoke(input_state, config={"recursion_limit": 200})
    print("ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ: ìµœì¢… ì¶œë ¥")
    
    # CSV ë‚´ìš© ì¶œë ¥
    csv_content = final_state["final_output"]
    print(csv_content)
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    filename = "bts_quiz_output.csv"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(csv_content)
    print(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
    
except Exception as e:
    print("ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ:", str(e))