import warnings
import os
# Suppress all deprecation warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)
# Also suppress via environment variable
os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'
from typing import TypedDict, Annotated, List
import operator
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_aws import ChatBedrock  # For Amazon Bedrock
from ddgs import DDGS
import json
import csv
from io import StringIO
from datetime import datetime
import time  # 지연 추가
from botocore.config import Config  # Config 임포트 추가

# OpenSearch 설정 및 함수들 import
from opensearch_config import (
    check_duplicate_in_opensearch,
    save_quiz_to_opensearch,
    get_opensearch_stats
)
from config import DEFAULT_DUPLICATION_THRESHOLD

# LLM setup - Using Amazon Bedrock Claude 3.7 Sonnet with cross-region inference
retry_config = Config(
    retries={
        'max_attempts': 10,
        'mode': 'adaptive'  # Exponential backoff for throttling
    }
)
llm = ChatBedrock(
    model_id="us.anthropic.claude-3-7-sonnet-20250219-v1:0",  # Claude 3.7 Sonnet cross-region profile
    region_name="us-east-1",  # Primary region; routes to us-east-1, us-east-2, us-west-2
    config=retry_config,
    # Add credentials if needed: credentials_profile_name="default"
)

# Current date
CURRENT_DATE = datetime(2025, 7, 25)

# Define quiz sub-task structure
class QuizSubTask(TypedDict):
    idol: str
    quiz_type: str  # e.g., "military_discharge", "latest_song"
    search_keyword: str  # Generated by LLM

# Global state
class State(TypedDict):
    topic: str  # User input topic
    all_subtasks: List[QuizSubTask]  # All subtasks to process
    current_subtask_index: int  # Current processing index
    current_subtask: QuizSubTask  # Currently processing subtask
    current_quiz: dict  # Currently generated quiz
    completed_quizzes: Annotated[List[dict], operator.add]  # Aggregated quizzes
    final_output: str  # Final CSV string
    
    # Control flags
    all_completed: bool  # All subtasks completed
    retry_feedback: str  # Feedback for retry from validation
    validation_success: bool  # Validation success flag
    duplication_check_success: bool  # Duplication check success flag
    retry_count: int  # Current retry count for current subtask

# Worker state is no longer needed - using main State for everything

# Orchestrator node: Manages quiz types sequentially
def orchestrator(state: State):
    # 초기 실행: 전체 subtasks 생성
    if 'topic' in state and not state.get('all_subtasks'):
        print("[orch]오케스트레이터 시작: 토픽 처리 중 -", state['topic'])
        time.sleep(1)
        topic = state['topic']
        
        # LLM prompt to generate sub-tasks
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="당신은 K-pop 아이돌 퀴즈 생성을 위한 오케스트레이터입니다. 현재 날짜: 2025-07-25. 주제를 분석하고 3-5개의 하위 작업을 JSON 배열로 생성하세요. 각 객체는 idol, quiz_type (military_discharge, song_matching, latest_song, lyrics_blank, true_false, running_time, kpop_history, fill_blank 중 선택), search_keyword 키를 포함해야 합니다. JSON 배열만 출력하세요."),
            HumanMessage(content=f"주제: {topic}")
        ])
        print("[orch]LLM 호출: sub-task 생성 중...")
        response = llm.invoke(prompt.format_messages())
        print("[orch]LLM 응답 원본:", response.content)
        
        try:
            quiz_subtasks = json.loads(response.content.strip())
            print("[orch]sub-tasks 생성 완료:", quiz_subtasks)
            
            return {
                "all_subtasks": quiz_subtasks,
                "current_subtask_index": 0,
                "current_subtask": quiz_subtasks[0],
                "retry_count": 0
            }
        except json.JSONDecodeError:
            print("[orch]JSON 파싱 에러 발생")
            return {"all_subtasks": [], "all_completed": True}
    
    # 퀴즈 완료 후: 다음 퀴즈타입으로 이동
    elif state.get('completed_quizzes') and not state.get('all_completed'):
        current_index = state.get('current_subtask_index', 0)
        next_index = current_index + 1
        all_subtasks = state.get('all_subtasks', [])
        
        if next_index < len(all_subtasks):
            print(f"[orch]다음 퀴즈타입 시작: {next_index + 1}/{len(all_subtasks)}")
            return {
                "current_subtask_index": next_index,
                "current_subtask": all_subtasks[next_index],
                "retry_feedback": "",  # 새 퀴즈타입이므로 피드백 초기화
                "retry_count": 0  # 새 퀴즈타입이므로 재시도 횟수 초기화
            }
        else:
            print("[orch]모든 퀴즈타입 완료")
            return {"all_completed": True}
    
    # 이미 완료된 경우
    else:
        return {"all_completed": True}

# Search and Generate worker: Combines search and quiz generation with retry feedback
def search_and_generate(state: State):
    subtask = state['current_subtask']
    retry_feedback = state.get('retry_feedback', '')
    
    if retry_feedback:
        print(f"[search_gen]재시도 시작: {subtask['idol']} - {subtask['quiz_type']}")
        print(f"[search_gen]피드백: {retry_feedback}")
    else:
        print(f"[search_gen]검색+생성 워커 시작: {subtask['idol']} - {subtask['quiz_type']}")
    
    # Step 1: Search
    print("[search_gen]1단계: 검색 시작")
    time.sleep(1)
    
    # Generate optimal search keyword (피드백 고려)
    search_prompt_content = "퀴즈 유형과 아이돌을 기반으로 DuckDuckGo API에 최적화된 검색 키워드를 한국어로 생성하세요. 관련이 있다면 현재 날짜 2025-07-25를 포함하세요. 키워드 문자열만 출력하세요."
    if retry_feedback:
        search_prompt_content += f" 이전 시도가 다음 피드백으로 실패했습니다: {retry_feedback}. 이에 따라 검색 전략을 조정하세요."
    
    search_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=search_prompt_content),
        HumanMessage(content=f"아이돌: {subtask['idol']}, 유형: {subtask['quiz_type']}, 초기 키워드: {subtask['search_keyword']}")
    ])

    print(f"[search_gen]-[search_prompt] : {search_prompt}")

    refined_keyword = llm.invoke(search_prompt.format_messages()).content.strip()
    
    
    # Perform search with Korean region
    print(f"[search_gen]한국어 검색 실행: {refined_keyword}")
    try:
        with DDGS() as ddgs:
            search_results = ddgs.text(
                query=refined_keyword,
                region="kr-kr",  # 한국어 region 설정
                max_results=5
            )
            # 검색 결과를 문자열로 변환
            results = ""
            for i, result in enumerate(search_results):
                results += f"제목: {result.get('title', '')}\n"
                results += f"내용: {result.get('body', '')}\n"
                results += f"URL: {result.get('href', '')}\n\n"
            print(f"[search_gen]검색 결과 수신: {search_results}개 결과")
    except Exception as e:
        print(f"[search_gen]검색 오류: {e}")
        results = "검색 결과를 가져올 수 없습니다."
    
    # Parse search results
    time.sleep(1)
    parse_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="검색 결과를 관련 정보(예: 전역일, 노래, 가사)가 포함된 JSON으로 파싱하세요. 2025-07-25 날짜를 기준으로 필터링하세요. JSON만 출력하세요."),
        HumanMessage(content=f"검색 결과: {results}")
    ])
    parsed_data = llm.invoke(parse_prompt.format_messages()).content.strip()
    
    try:
        # Clean JSON from markdown blocks
        if "```json" in parsed_data:
            parsed_data = parsed_data.split("```json")[1].split("```")[0].strip()
        elif "```" in parsed_data:
            parsed_data = parsed_data.split("```")[1].strip()
        data = json.loads(parsed_data)
        print("[search_gen]검색 데이터 파싱 완료")
    except json.JSONDecodeError:
        print(f"[search_gen]검색 데이터 파싱 실패: {parsed_data[:100]}...")
        data = {}
    
    # Step 2: Generate Quiz (피드백 고려)
    print("[search_gen]2단계: 퀴즈 생성 시작")
    time.sleep(1)
    
    quiz_prompt_content = "기반 데이터를 참고해서 K-pop 퀴즈를 JSON 형식으로 생성하세요: {'QuizID': int, 'Category': str, 'QuestionID': int, 'Type': str, 'Question': str, 'Options': list[str], 'IsCorrect': str}. 2개 또는 4개 선택지를 사용하거나 빈칸 문제로 만드세요. 기준 날짜: 2025-07-25. JSON만 출력하세요."
    if retry_feedback:
        quiz_prompt_content += f" 이전 퀴즈가 다음 피드백으로 거부되었습니다: {retry_feedback}. 새 퀴즈에서 이러한 문제를 해결해주세요."
    
    quiz_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=quiz_prompt_content),
        HumanMessage(content=f"유형: {subtask['quiz_type']}, 아이돌: {subtask['idol']}, 기반 데이터: {data}")
    ])
    quiz_json = llm.invoke(quiz_prompt.format_messages()).content.strip()
    
    try:
        # Clean JSON from markdown blocks
        if "```json" in quiz_json:
            quiz_json = quiz_json.split("```json")[1].split("```")[0].strip()
        elif "```" in quiz_json:
            quiz_json = quiz_json.split("```")[1].strip()
        quiz = json.loads(quiz_json)
        print(f"[search_gen]퀴즈 생성 완료: {quiz}")
    except json.JSONDecodeError:
        print(f"[search_gen]퀴즈 생성 파싱 실패: {quiz_json[:100]}...")
        quiz = {}
    
    result_msg = "재시도 완료" if retry_feedback else "검색+생성 완료"
    print(f"[search_gen]{result_msg}: {subtask['idol']} - {'성공' if quiz else '실패'}")
    
    return {"current_quiz": quiz if quiz else None}

# OpenSearch Duplication Checker: 중복 퀴즈 검사
def os_duplication_checker(state: State):
    print("[dup]OpenSearch 중복 검사 워커 시작...")
    print(f"[dup]State 키들: {list(state.keys())}")
    
    quiz = state.get('current_quiz')
    
    if not quiz:
        print("[dup]검사할 퀴즈가 없습니다")
        # 재시도 횟수 확인
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:
            print(f"[dup]최대 재시도 횟수 초과 ({retry_count}번), 다음 퀴즈타입으로 이동")
            return {"duplication_check_success": True, "retry_count": 0, "retry_feedback": ""}
        
        return {"retry_feedback": "퀴즈 생성에 실패했습니다. 다시 시도해주세요.", "retry_count": retry_count + 1, "duplication_check_success": False}
    
    print(f"[dup]중복 검사 대상 퀴즈: {quiz.get('Question', '')}")
    
    # OpenSearch 중복 검사 수행
    question_text = quiz.get('Question', '')
    if not question_text:
        print("[dup]질문 텍스트가 없어 중복 검사를 건너뜁니다")
        return {"duplication_check_success": True, "retry_feedback": ""}
    
    try:
        print(f"[dup]OpenSearch에서 중복 퀴즈 검사 중... (임계값: {DEFAULT_DUPLICATION_THRESHOLD})")
        is_duplicate, duplicates, error = check_duplicate_in_opensearch(question_text, threshold=DEFAULT_DUPLICATION_THRESHOLD)
        
        if error:
            print(f"[dup]OpenSearch 중복 검사 오류: {error}")
            # 오류 발생 시에도 다음 단계로 진행 (검증은 계속)
            return {"duplication_check_success": True, "retry_feedback": ""}
        
        if is_duplicate:
            print(f"[dup]🚨 중복 퀴즈 발견! {len(duplicates)}개의 유사한 퀴즈 존재")
            
            # 현재 퀴즈 정보 수집
            current_quiz_info = f"""📝 현재 생성된 퀴즈:
질문: '{question_text}'
정답: '{quiz.get('IsCorrect', '')}'
카테고리: {quiz.get('Category', '')}"""
            
            # 중복 퀴즈 정보 출력 및 수집
            duplicate_info = []
            for i, dup in enumerate(duplicates[:3], 1):  # 상위 3개만
                duplicate_info.append(f"{i}. '{dup['question']}' (유사도: {dup['cosine_similarity']:.3f})")
                print(f"[dup]  유사 퀴즈 {i}: {dup['question']} (유사도: {dup['cosine_similarity']:.3f})")
            
            # 재시도 횟수 확인
            retry_count = state.get('retry_count', 0)
            if retry_count >= 3:
                print(f"[dup]최대 재시도 횟수 초과 ({retry_count}번), 중복 퀴즈 처리 - 다음 퀴즈타입으로 이동")
                return {"duplication_check_success": True, "retry_count": 0, "retry_feedback": ""}
            
            # 중복 피드백 생성 (현재 퀴즈 정보 포함)
            duplicate_feedback = f"""🚨 중복 퀴즈 감지됨! (유사도 임계값: {DEFAULT_DUPLICATION_THRESHOLD})

{current_quiz_info}

🔍 기존 유사 퀴즈들:
{chr(10).join(duplicate_info)}

💡 해결 방안: 
- 다른 각도에서 접근하는 완전히 새로운 퀴즈를 만들어주세요
- 더 구체적인 세부사항이나 다른 측면을 다루는 퀴즈로 변경해주세요
- 시간대, 상황, 맥락 등을 다르게 하여 차별화된 퀴즈를 생성해주세요"""
            
            print(f"[dup]중복 검사 실패 - search_and_generate로 재시도 요청")
            return {
                "retry_feedback": duplicate_feedback, 
                "retry_count": retry_count + 1, 
                "duplication_check_success": False
            }
        else:
            print("[dup]✅ 중복 검사 통과 - 새로운 퀴즈입니다!")
            return {"duplication_check_success": True, "retry_feedback": ""}
            
    except Exception as e:
        print(f"[dup]OpenSearch 중복 검사 예외 발생: {e}")
        # 예외 발생 시에도 다음 단계로 진행
        return {"duplication_check_success": True, "retry_feedback": ""}

# Validation worker: Validates quiz and routes based on success/failure
def validation_worker(state: State):
    print("[val]검증 워커 시작: 퀴즈 검증 중...")
    print(f"[val]State 키들: {list(state.keys())}")
    print(f"[val]current_quiz 존재 여부: {'current_quiz' in state}")
    time.sleep(1)
    quiz = state.get('current_quiz')
    
    if not quiz:
        print("[val]검증할 퀴즈가 없습니다")
        print(f"[val]current_quiz 값: {quiz}")
        
        # 재시도 횟수 확인
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:  # 최대 3번 재시도
            print(f"[val]최대 재시도 횟수 초과 ({retry_count}번), 퀴즈 생성 실패 처리 - 다음 퀴즈타입으로 이동")
            return {"completed_quizzes": [], "validation_success": True, "retry_count": 0, "retry_feedback": ""}  # 빈 퀴즈로 다음으로 이동
        
        return {"retry_feedback": "퀴즈 생성에 실패했습니다. 다시 시도해주세요.", "retry_count": retry_count + 1}
    
    print(f"[val]퀴즈 발견: {quiz}")
    
    # Step 1: Generate multiple validation keywords using LLM
    print("[val]1단계: 검증용 키워드 생성")
    keyword_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="주어진 퀴즈를 검증하기 위한 3-5개의 검색 키워드를 생성하세요. 각 키워드는 퀴즈의 다른 측면을 검증할 수 있어야 합니다. JSON 배열 형태로 반환하세요. 예: [\"키워드1\", \"키워드2\", \"키워드3\"]"),
        HumanMessage(content=f"퀴즈: {json.dumps(quiz, ensure_ascii=False)}")
    ])
    
    try:
        keyword_response = llm.invoke(keyword_prompt.format_messages()).content.strip()
        # Clean JSON from markdown blocks
        if "```json" in keyword_response:
            keyword_response = keyword_response.split("```json")[1].split("```")[0].strip()
        elif "```" in keyword_response:
            keyword_response = keyword_response.split("```")[1].strip()
        
        validation_keywords = json.loads(keyword_response)
        print(f"[val]검증 키워드 생성 완료: {validation_keywords}")
    except json.JSONDecodeError:
        print(f"[val]키워드 생성 실패, 기본 키워드 사용: {keyword_response[:100]}...")
        # 기본 키워드 생성
        key_fact = quiz.get('IsCorrect', '')
        question = quiz.get('Question', '')
        validation_keywords = [
            f"{key_fact}",
            f"{question}",
            f"K-pop {quiz.get('Category', '')}"
        ]
    
    # Step 2: Perform multiple searches with different keywords
    print("[val]2단계: 다중 키워드 검색 실행")
    all_search_results = []
    
    for i, keyword in enumerate(validation_keywords):
        print(f"[val]검색 {i+1}/{len(validation_keywords)}: {keyword}")
        try:
            with DDGS() as ddgs:
                search_results = ddgs.text(
                    query=keyword,
                    region="kr-kr",  # 한국어 region 설정
                    max_results=2  # 키워드당 2개씩
                )
                
                for result in search_results:
                    all_search_results.append({
                        'keyword': keyword,
                        'title': result.get('title', ''),
                        'body': result.get('body', ''),
                        'url': result.get('href', '')
                    })
                    
            print(f"[val]키워드 '{keyword}' 검색 완료: {len(search_results)}개 결과")
            time.sleep(0.5)  # 검색 간 지연
            
        except Exception as e:
            print(f"[val]키워드 '{keyword}' 검색 오류: {e}")
            continue
    
    print(f"[val]전체 검색 결과 수집 완료: {len(all_search_results)}개 결과")
    
    # Step 3: Aggregate and format search results
    print("[val]3단계: 검색 결과 취합 및 검증")
    aggregated_results = ""
    for i, result in enumerate(all_search_results):
        aggregated_results += f"[키워드: {result['keyword']}]\n"
        aggregated_results += f"제목: {result['title']}\n"
        aggregated_results += f"내용: {result['body']}\n"
        aggregated_results += f"URL: {result['url']}\n\n"
    
    # Step 4: LLM validation with aggregated search results
    time.sleep(1)
    validate_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="당신은 퀴즈가 틀린 정보로 만들어졌는지 검증하는 검증자입니다. 여러 키워드로 수집된 검색 결과를 종합하여 퀴즈의 정확성을 검증하세요. 다양한 소스에서 일관된 정보가 확인되면 'VALID'를 반환하고, 모순되거나 확인되지 않으면 'INVALID: [구체적인 틀린 이유]'를 반환하세요. 2025-07-25 날짜를 기준으로 교차 확인하세요."),
        HumanMessage(content=f"퀴즈: {json.dumps(quiz, ensure_ascii=False)}\n\n다중 키워드 검색 결과:\n{aggregated_results}")
    ])
    validated = llm.invoke(validate_prompt.format_messages()).content.strip()
    print(f"[val]종합 검증 응답: {validated}")
    
    if "INVALID" in validated.upper():
        # 재시도 횟수 확인
        retry_count = state.get('retry_count', 0)
        if retry_count >= 3:  # 최대 3번 재시도
            print(f"[val]최대 재시도 횟수 초과 ({retry_count}번), 퀴즈 검증 실패 처리 - 다음 퀴즈타입으로 이동")
            return {"completed_quizzes": [], "validation_success": True, "retry_count": 0, "retry_feedback": ""}  # 빈 퀴즈로 다음으로 이동
        
        # 실패: search_and_generate로 피드백과 함께 재시도
        feedback = validated.replace("INVALID:", "").strip()
        print(f"[val]퀴즈 검증 실패: {feedback}")
        return {"retry_feedback": feedback, "retry_count": retry_count + 1, "validation_success": False}  # validation_success=False 추가
    else:
        # 성공: orchestrator로 결과 전달
        print("[val]퀴즈 검증 성공")
        return {"completed_quizzes": [quiz], "validation_success": True, "retry_count": 0, "retry_feedback": ""}

# Display worker: Synthesizes quizzes into CSV
def display_worker(state: State):
    print("[dp]표시 워커 시작: OpenSearch 저장 후 CSV 생성 중...")
    quizzes = state['completed_quizzes']
    
    print(f"[dp]CSV 생성 완료: 퀴즈 개수 {len(quizzes)}")
    
    # ===== 1단계: OpenSearch에 퀴즈 저장 =====
    print("[dp]1단계: OpenSearch에 퀴즈 저장 중...")
    opensearch_success_count = 0
    opensearch_fail_count = 0
    
    for i, quiz in enumerate(quizzes, 1):
        print(f"[dp]OpenSearch 저장 {i}/{len(quizzes)}: {quiz.get('Question', '')[:50]}...")
        
        success, doc_id, error = save_quiz_to_opensearch(quiz)
        
        if success:
            opensearch_success_count += 1
            print(f"[dp]  ✅ 저장 성공 (ID: {doc_id})")
        else:
            opensearch_fail_count += 1
            print(f"[dp]  ❌ 저장 실패: {error}")
    
    print(f"[dp]OpenSearch 저장 완료: 성공 {opensearch_success_count}개, 실패 {opensearch_fail_count}개")
    
    # ===== 2단계: CSV 생성 =====
    print("[dp]2단계: CSV 파일 생성 중...")
    output = StringIO()
    writer = csv.DictWriter(output, fieldnames=["QuizID", "Category", "QuestionID", "Type", "Question", "Option", "IsCorrect"])
    writer.writeheader()
    
    for quiz in quizzes:
        # CSV 행 생성
        for option in quiz.get('Options', []):
            row = {
                "QuizID": quiz.get('QuizID', ''),
                "Category": quiz.get('Category', ''),
                "QuestionID": quiz.get('QuestionID', ''),
                "Type": quiz.get('Type', ''),
                "Question": quiz.get('Question', ''),
                "Option": option,
                "IsCorrect": "Y" if option == quiz.get('IsCorrect', '') else ""
            }
            writer.writerow(row)
    
    final_csv = output.getvalue()
    
    # ===== 3단계: CSV 파일 저장 =====
    topic = state.get('topic', 'quiz')
    safe_topic = topic.replace(' ', '_').replace('/', '_').lower()
    filename = f"{safe_topic}_quiz_output.csv"
    
    try:
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            f.write(final_csv)
        print(f"[dp]CSV 파일 저장 완료: {filename}")
    except Exception as e:
        print(f"[dp]CSV 파일 저장 실패: {e}")
    
    print(f"[dp]표시 워커 완료: OpenSearch {opensearch_success_count}개 저장, CSV 파일 생성")
    return {"final_output": final_csv}

# Routing functions
def route_after_validation(state: State):
    retry_feedback = state.get('retry_feedback', '')
    validation_success = state.get('validation_success', False)
    
    print(f"[route]라우팅 체크: retry_feedback='{retry_feedback}', validation_success={validation_success}")
    
    if validation_success:
        return "success"  # validation_success가 True면 무조건 성공으로
    elif retry_feedback and retry_feedback.strip():  # 빈 문자열이 아닌 경우만 재시도
        return "retry"  # 실패시 search_and_generate로 재시도
    else:
        return "retry"  # 기본값

def route_after_orchestrator(state: State):
    if state.get('all_completed'):
        return "display"  # 모든 퀴즈 완료시 display_worker로
    else:
        return "generate"  # 다음 퀴즈타입 처리

# Conditional edge: No longer needed for parallel processing
def assign_workers(state: State):
    # This function is no longer used in sequential processing
    return []

# Routing functions
def route_after_orchestrator(state: State):
    print(f"[route]오케스트레이터 후 라우팅: all_completed={state.get('all_completed', False)}")
    if state.get('all_completed', False):
        return "display"
    else:
        return "generate"

def route_after_duplication_check(state: State):
    """중복 검사 후 라우팅"""
    duplication_success = state.get('duplication_check_success', True)
    retry_feedback = state.get('retry_feedback', '')
    
    print(f"[route]중복 검사 후 라우팅: duplication_success={duplication_success}, retry_feedback='{retry_feedback[:50]}...'")
    
    if duplication_success:
        return "validation"  # 중복 검사 통과 → 기존 검증으로
    else:
        return "retry"  # 중복 발견 → 재시도

def route_after_validation(state: State):
    validation_success = state.get('validation_success', False)
    retry_feedback = state.get('retry_feedback', '')
    
    print(f"[route]라우팅 체크: retry_feedback='{retry_feedback}', validation_success={validation_success}")
    
    if validation_success:
        return "success"
    else:
        return "retry"

# Build the graph
builder = StateGraph(State)

builder.add_node("orchestrator", orchestrator)
builder.add_node("search_and_generate", search_and_generate)
builder.add_node("os_duplication_checker", os_duplication_checker)  # 새로운 중복 검사 노드
builder.add_node("validation_worker", validation_worker)
builder.add_node("display_worker", display_worker)

# 라우팅 설정
builder.add_edge(START, "orchestrator")
builder.add_conditional_edges("orchestrator", route_after_orchestrator, 
                             {"generate": "search_and_generate", "display": "display_worker"})
builder.add_edge("search_and_generate", "os_duplication_checker")  # 생성 후 중복 검사
builder.add_conditional_edges("os_duplication_checker", route_after_duplication_check,
                             {"validation": "validation_worker", "retry": "search_and_generate"})  # 중복 검사 후 분기
builder.add_conditional_edges("validation_worker", route_after_validation,
                             {"retry": "search_and_generate", "success": "orchestrator"})
builder.add_edge("display_worker", END)

graph = builder.compile()

# Invoke example
input_state = {"topic": "Generate 5 quizzes about BTS"}
print("그래프 실행 시작: 전체 프로세스 시작")
try:
    final_state = graph.invoke(input_state, config={"recursion_limit": 200})
    print("그래프 실행 완료: 최종 출력")
    
    # CSV 내용 출력
    csv_content = final_state["final_output"]
    print(csv_content)
    
    # CSV 파일로 저장
    filename = "bts_quiz_output.csv"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(csv_content)
    print(f"CSV 파일 저장 완료: {filename}")
    
except Exception as e:
    print("그래프 실행 중 에러 발생:", str(e))